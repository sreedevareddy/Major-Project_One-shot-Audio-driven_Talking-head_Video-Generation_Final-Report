{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30716,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-02T08:27:34.696584Z","iopub.execute_input":"2024-06-02T08:27:34.696855Z","iopub.status.idle":"2024-06-02T08:27:35.590313Z","shell.execute_reply.started":"2024-06-02T08:27:34.696831Z","shell.execute_reply":"2024-06-02T08:27:35.589384Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Install required libraries\n!pip install git+https://github.com/openai/whisper.git\n!pip install fairseq","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:27:35.591919Z","iopub.execute_input":"2024-06-02T08:27:35.592452Z","iopub.status.idle":"2024-06-02T08:29:18.795388Z","shell.execute_reply.started":"2024-06-02T08:27:35.592416Z","shell.execute_reply":"2024-06-02T08:29:18.794466Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/whisper.git\n  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-u471lmcx\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-u471lmcx\n  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.4)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.4)\nRequirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (10.2.0)\nCollecting tiktoken (from openai-whisper==20231117)\n  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting triton<3,>=2.0.0 (from openai-whisper==20231117)\n  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\nRequirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2024.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\nDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: openai-whisper\n  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=72452ce395fd1593c870e2d894c7c91752d0cc483dd90f941f28e8f177855388\n  Stored in directory: /tmp/pip-ephem-wheel-cache-76vbim5z/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\nSuccessfully built openai-whisper\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: triton, tiktoken, openai-whisper\nSuccessfully installed openai-whisper-20231117 tiktoken-0.7.0 triton-2.3.1\nCollecting fairseq\n  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.16.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq) (3.0.8)\nCollecting hydra-core<1.1,>=1.0.7 (from fairseq)\n  Downloading hydra_core-1.0.7-py3-none-any.whl.metadata (3.7 kB)\nCollecting omegaconf<2.1 (from fairseq)\n  Downloading omegaconf-2.0.6-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq) (2023.12.25)\nCollecting sacrebleu>=1.4.12 (from fairseq)\n  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq) (4.66.4)\nCollecting bitarray (from fairseq)\n  Downloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nRequirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from fairseq) (1.26.4)\nCollecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq)\n  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (6.0.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq) (4.9.0)\nCollecting portalocker (from sacrebleu>=1.4.12->fairseq)\n  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq) (5.2.2)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq) (2.21)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->fairseq) (2024.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->fairseq) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->fairseq) (1.3.0)\nDownloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\nDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading bitarray-2.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\nBuilding wheels for collected packages: fairseq, antlr4-python3-runtime\n  Building wheel for fairseq (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=10416014 sha256=eafb1ed515f855c26cfd79e7f57b59ba9fa157f179bfe4dea62d4ff830f1a71b\n  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=3bea774509accb2310c3d0dde3cde3a13425aa7ede39b0239bf734a05bfac390\n  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\nSuccessfully built fairseq antlr4-python3-runtime\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: bitarray, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, fairseq\nSuccessfully installed antlr4-python3-runtime-4.8 bitarray-2.9.2 fairseq-0.12.2 hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.8.2 sacrebleu-2.4.2\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone https://github.com/pytorch/fairseq.git\n%cd fairseq\n!pip install --editable ./","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:35:14.514020Z","iopub.execute_input":"2024-06-02T08:35:14.514865Z","iopub.status.idle":"2024-06-02T08:45:28.990960Z","shell.execute_reply.started":"2024-06-02T08:35:14.514833Z","shell.execute_reply":"2024-06-02T08:45:28.989803Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Cloning into 'fairseq'...\nremote: Enumerating objects: 35196, done.\u001b[K\nremote: Counting objects: 100% (117/117), done.\u001b[K\nremote: Compressing objects: 100% (69/69), done.\u001b[K\nremote: Total 35196 (delta 64), reused 79 (delta 48), pack-reused 35079\u001b[K\nReceiving objects: 100% (35196/35196), 25.22 MiB | 31.46 MiB/s, done.\nResolving deltas: 100% (25551/25551), done.\n/kaggle/working/fairseq\nObtaining file:///kaggle/working/fairseq\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: cffi in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (1.16.0)\nRequirement already satisfied: cython in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (3.0.8)\nRequirement already satisfied: hydra-core<1.1,>=1.0.7 in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (1.0.7)\nRequirement already satisfied: omegaconf<2.1 in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (2.0.6)\nRequirement already satisfied: numpy>=1.21.3 in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (1.26.4)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (2023.12.25)\nRequirement already satisfied: sacrebleu>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (2.4.2)\nRequirement already satisfied: torch>=1.13 in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (4.66.4)\nRequirement already satisfied: bitarray in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (2.9.2)\nRequirement already satisfied: torchaudio>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (2.1.2)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (1.2.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from fairseq==0.12.2) (21.3)\nRequirement already satisfied: antlr4-python3-runtime==4.8 in /opt/conda/lib/python3.10/site-packages (from hydra-core<1.1,>=1.0.7->fairseq==0.12.2) (4.8)\nRequirement already satisfied: PyYAML>=5.1.* in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==0.12.2) (6.0.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from omegaconf<2.1->fairseq==0.12.2) (4.9.0)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (2.8.2)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->fairseq==0.12.2) (5.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->fairseq==0.12.2) (3.13.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->fairseq==0.12.2) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->fairseq==0.12.2) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->fairseq==0.12.2) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.13->fairseq==0.12.2) (2024.3.1)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi->fairseq==0.12.2) (2.21)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->fairseq==0.12.2) (3.1.1)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fairseq==0.12.2) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fairseq==0.12.2) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->fairseq==0.12.2) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13->fairseq==0.12.2) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13->fairseq==0.12.2) (1.3.0)\nBuilding wheels for collected packages: fairseq\n  Building editable for fairseq (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for fairseq: filename=fairseq-0.12.2-0.editable-cp310-cp310-linux_x86_64.whl size=9571 sha256=9aaabe67defb51f7db3a0ebd2c28b967019b29586583a487cbfac8eeed385e27\n  Stored in directory: /tmp/pip-ephem-wheel-cache-5e9i6tj_/wheels/67/69/06/aa788a7d879a7513f5f2e5c6d56825b6813783cb55ac5c7f8d\nSuccessfully built fairseq\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: fairseq\n  Attempting uninstall: fairseq\n    Found existing installation: fairseq 0.12.2\n    Uninstalling fairseq-0.12.2:\n      Successfully uninstalled fairseq-0.12.2\nSuccessfully installed fairseq-0.12.2\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import necessary libraries\nimport whisper\nimport torch\nfrom fairseq.models import RagModel, RagTokenizer\n\n# Load the Whisper model\nmodel = whisper.load_model(\"base\")\n\n# Load the RAG model and tokenizer\nrag_model = RagModel.from_pretrained(\"facebook/rag-token-base\")\nrag_tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n\n# Define a function to transcribe audio\ndef transcribe_audio(audio_file):\n    audio = whisper.load_audio(audio_file)\n    audio = whisper.pad_or_trim(audio)\n    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n    options = whisper.DecodingOptions(language=\"multilingual\")\n    result = whisper.decode(model, mel, options)\n    return result.text\n\n# Define a function to translate text using RAG\ndef translate_text(text, source_lang, target_lang):\n    rag_input = rag_tokenizer.encode(text, source_lang=source_lang, target_lang=target_lang)\n    rag_output = rag_model.generate(rag_input, target_lang=target_lang)\n    translation = rag_tokenizer.decode(rag_output, target_lang=target_lang)\n    return translation\n\n# Define a function to summarize text using RAG\ndef summarize_text(text, max_length=100):\n    rag_input = rag_tokenizer.encode(text)\n    rag_output = rag_model.generate(rag_input, max_length=max_length)\n    summary = rag_tokenizer.decode(rag_output)\n    return summary\n\n","metadata":{"execution":{"iopub.status.busy":"2024-06-02T08:54:18.462962Z","iopub.execute_input":"2024-06-02T08:54:18.463795Z","iopub.status.idle":"2024-06-02T08:54:18.520216Z","shell.execute_reply.started":"2024-06-02T08:54:18.463762Z","shell.execute_reply":"2024-06-02T08:54:18.519139Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwhisper\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rag, RagModel, RagTokenizer\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the Whisper model\u001b[39;00m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m whisper\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Rag' from 'fairseq.models' (/opt/conda/lib/python3.10/site-packages/fairseq/models/__init__.py)"],"ename":"ImportError","evalue":"cannot import name 'Rag' from 'fairseq.models' (/opt/conda/lib/python3.10/site-packages/fairseq/models/__init__.py)","output_type":"error"}]},{"cell_type":"code","source":"# Example usage\naudio_file = \"/path/to/audio/file.wav\"\ntranscribed_text = transcribe_audio(audio_file)\ntranslation = translate_text(transcribed_text, source_lang=\"en\", target_lang=\"fr\")\nsummary = summarize_text(transcribed_text)\n\nprint(\"Transcribed Text:\", transcribed_text)\nprint(\"Translation:\", translation)\nprint(\"Summary:\", summary)","metadata":{},"execution_count":null,"outputs":[]}]}